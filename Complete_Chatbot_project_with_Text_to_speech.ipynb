{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lambhua/NLP-Project/blob/main/Complete_Chatbot_project_with_Text_to_speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the required Libraries**"
      ],
      "metadata": {
        "id": "kc-vBEl-f5aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import nltk\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from gtts import gTTS  # for text to speech"
      ],
      "metadata": {
        "id": "J3pykTsNfnv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klEyt_vYfP6T"
      },
      "outputs": [],
      "source": [
        "#importing the dataset\n",
        "# imported content.json from chatbot folder\n",
        "#content.json on desktop under construction\n",
        "with open(r'C:\\Users\\HP\\Desktop\\content.json') as content:\n",
        "  data1 = json.load(content,strict=False)\n",
        "\n",
        "#getting all the data to lists\n",
        "tags = []\n",
        "inputs = []\n",
        "responses={}\n",
        "for intent in data1['intents']:\n",
        "  responses[intent['tag']]=intent['responses']\n",
        "  for lines in intent['input']:\n",
        "    inputs.append(lines)\n",
        "    tags.append(intent['tag'])\n",
        "\n",
        "#converting to dataframe\n",
        "data = pd.DataFrame({\"inputs\":inputs,\n",
        "                     \"tags\":tags})\n",
        "\n",
        "data = data.sample(frac=1)\n",
        "\n",
        "#removing punctuations\n",
        "import string\n",
        "data['inputs'] = data['inputs'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
        "data['inputs'] = data['inputs'].apply(lambda wrd: ''.join(wrd))\n",
        "data\n",
        "\n",
        "#tokenize the data\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(data['inputs'])\n",
        "train = tokenizer.texts_to_sequences(data['inputs'])\n",
        "#apply padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = pad_sequences(train)\n",
        "\n",
        "#encoding the outputs\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(data['tags'])\n",
        "\n",
        "input_shape = x_train.shape[1]\n",
        "print(input_shape)\n",
        "\n",
        "#define vocabulary\n",
        "vocabulary = len(tokenizer.word_index)\n",
        "print(\"number of unique words : \",vocabulary)\n",
        "output_length = le.classes_.shape[0]\n",
        "print(\"output length: \",output_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3zHCXFYfP6V"
      },
      "outputs": [],
      "source": [
        "#creating the model\n",
        "\n",
        "i = Input(shape=(input_shape,))\n",
        "x = Embedding(vocabulary+1,10)(i)\n",
        "x = LSTM(10,return_sequences=True)(x) # return sequences to true because we wants hidden state in output at each time step\n",
        "x = Flatten()(x)\n",
        "x = Dense(output_length,activation=\"softmax\")(x)\n",
        "model  = Model(i,x)\n",
        "\n",
        "#compiling the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#training the model\n",
        "train = model.fit(x_train,y_train,epochs=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoM5f6B_fP6W"
      },
      "outputs": [],
      "source": [
        "# text to speech function\n",
        "def text_to_speech(text):\n",
        "    # Initialize gTTS with the text to convert\n",
        "    speech = gTTS(text = text, lang='en', slow = False)\n",
        "\n",
        "    # Save the audio file to a temporary file\n",
        "    speech_file = 'speech.mp3'\n",
        "    speech.save(speech_file)\n",
        "\n",
        "\n",
        "    # Play the audio file\n",
        "    os.system(speech_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa78a2ONfP6X"
      },
      "outputs": [],
      "source": [
        "#chatting\n",
        "import random\n",
        "while True:\n",
        "  texts_p = []\n",
        "  prediction_input = input('You : ')\n",
        "\n",
        "  #removing punctuation and converting to lowercase\n",
        "  prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
        "  prediction_input = ''.join(prediction_input)\n",
        "  texts_p.append(prediction_input)\n",
        "\n",
        "  #tokenizing and padding\n",
        "  prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "  prediction_input = np.array(prediction_input).reshape(-1)\n",
        "  prediction_input = pad_sequences([prediction_input],input_shape)\n",
        "\n",
        "  #getting output from model\n",
        "  output = model.predict(prediction_input)\n",
        "  output = output.argmax()\n",
        "\n",
        "  #finding the right tag and predicting\n",
        "  response_tag = le.inverse_transform([output])[0]\n",
        "  resp=random.choice(responses[response_tag])\n",
        "  print(resp)\n",
        "  text_to_speech(resp)\n",
        "\n",
        "  if response_tag == \"goodbye\":\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOm9B7fXfP6Z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}